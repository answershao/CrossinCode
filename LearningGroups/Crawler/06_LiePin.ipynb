{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始职位详细页爬取\n",
      "开始职位详细页爬取\n",
      "page1\n",
      "https://www.liepin.com//zhaopin/?compkind=&dqs=&pubTime=&pageSize=40&salary=&compTag=&sortFlag=&degradeFlag=0&compIds=&subIndustry=&jobKind=&industries=&compscale=&key=python&siTag=I-7rQ0e90mv8a37po7dV3Q%7EfA9rXquZc5IkJpXC-Ycixw&d_sfrom=search_fp&d_ckId=38454c11b7ea1dd370fa8cf95bd5e4fa&d_curPage=0&d_pageSize=40&d_headId=38454c11b7ea1dd370fa8cf95bd5e4fa&curPage=1\n",
      "开始职位详细页爬取\n",
      "开始职位详细页爬取\n",
      "page2\n",
      "https://www.liepin.com//zhaopin/?compkind=&dqs=&pubTime=&pageSize=40&salary=&compTag=&sortFlag=&degradeFlag=0&compIds=&subIndustry=&jobKind=&industries=&compscale=&key=python&siTag=I-7rQ0e90mv8a37po7dV3Q%7EfA9rXquZc5IkJpXC-Ycixw&d_sfrom=search_fp&d_ckId=38454c11b7ea1dd370fa8cf95bd5e4fa&d_curPage=1&d_pageSize=40&d_headId=38454c11b7ea1dd370fa8cf95bd5e4fa&curPage=2\n",
      "开始职位详细页爬取\n",
      "开始职位详细页爬取\n",
      "page3\n",
      "https://www.liepin.com//zhaopin/?compkind=&dqs=&pubTime=&pageSize=40&salary=&compTag=&sortFlag=&degradeFlag=0&compIds=&subIndustry=&jobKind=&industries=&compscale=&key=python&siTag=I-7rQ0e90mv8a37po7dV3Q%7EfA9rXquZc5IkJpXC-Ycixw&d_sfrom=search_fp&d_ckId=38454c11b7ea1dd370fa8cf95bd5e4fa&d_curPage=2&d_pageSize=40&d_headId=38454c11b7ea1dd370fa8cf95bd5e4fa&curPage=3\n",
      "开始职位详细页爬取\n",
      "开始职位详细页爬取\n",
      "page4\n",
      "完成\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv, time\n",
    "\n",
    "# 调用子函数会，出现bug，出现验证界面\n",
    "# def crawler(url, headers):\n",
    "#     r = requests.get(url, headers)\n",
    "#     soup = BeautifulSoup(r.text, 'lxml')\n",
    "#     print(url, headers)\n",
    "#     print(soup)\n",
    "#     print(soup.find_all(class_=\"content content-word\"))\n",
    "#     return soup.find_all(class_=\"content content-word\")[0].get_text().strip()\n",
    "\n",
    "next_page_url = 'https://www.liepin.com/zhaopin/?sfrom=click-pc_homepage-centre_searchbox-search_new&d_sfrom=search_fp&key=python'\n",
    "headers = {'user-agent':'chrome'}\n",
    "count = 1\n",
    "with open('06_hc.csv', 'w', encoding='utf-8') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    while next_page_url:\n",
    "        url = next_page_url    \n",
    "        r = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(r.text, 'lxml')\n",
    "#         print(soup.find_all(class_='sojob-result'))\n",
    "        current_page_job_list = soup.find_all(class_='sojob-result')[0]\n",
    "#         print(current_page_job_list)\n",
    "        data_info_s = current_page_job_list.find_all('li')\n",
    "#         for data_info in data_info_s:\n",
    "#         len(data_info_s)\n",
    "        for i in range(2):\n",
    "            data_info = data_info_s[i]\n",
    "#             print(data_info)\n",
    "            hc = data_info.find_all(class_='job-info')[0].h3['title'][2:]\n",
    "            sub_url = data_info.div.h3.a['href']\n",
    "#             print(hc, sub_url)\n",
    "#             job_description = crawler(sub_url, headers)\n",
    "            print('开始职位详细页爬取')\n",
    "            req = requests.get(sub_url, headers=headers)\n",
    "            sub_soup = BeautifulSoup(req.text, 'lxml')\n",
    "            job_description = sub_soup.find_all(class_=\"content content-word\")[0].get_text().strip()\n",
    "#             job_description = soup.find_all(class_=\"content content-word\")[0].get_text().strip()\n",
    "            # 薪水、学历要求、工作经验要求、招聘详细页url、公司名、公司 url\n",
    "            info = sub_soup.find_all(class_=\"job-title-left\")[0]\n",
    "            salary = info.p.get_text().strip().split()[0]\n",
    "            # line = [education, experience, language, age]\n",
    "            line = [x.get_text() for x in info.div.find_all('span')]\n",
    "            line.insert(0, salary)\n",
    "            line.append(job_description)\n",
    "#             print(line)\n",
    "#             print(sub_soup.find_all(class_=\"content content-word\"))\n",
    "#             job_description = sub_soup.find_all(class_=\"content content-word\")[0].get_text().strip()\n",
    "            line = [hc, job_description]         \n",
    "            f_csv.writerow(line)\n",
    "        print('page{}'.format(count))\n",
    "        count += 1\n",
    "        time.sleep(5)\n",
    "        if count < 5:\n",
    "            next_page_url = 'https://www.liepin.com/' + current_page_job_list.find_all(class_='pagerbar')[0].find_all('a')[-3]['href']\n",
    "            print(next_page_url)\n",
    "        if url == next_page_url:\n",
    "            break\n",
    "print('完成')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://www.liepin.com/job/1929302933.shtml'\n",
    "# url = 'https://www.liepin.com/zhaopin/?sfrom=click-pc_homepage-centre_searchbox-search_new&d_sfrom=search_fp&key=python'\n",
    "headers = {'user-agent':'chrome'}\n",
    "r = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20-30k·12薪', '本科及以上', '经验不限', '语言不限', '年龄不限', '岗位职责：1.负责  等产品的服务端研发；2.深入发掘和分析业务需求，撰写技术方案和系统设计；3.根据产品需求，进行系统设计和编码；4.持续对系统架构进行改造和优化；职位要求：1.三年以上开发经验，一年以上的Python开发经验；2.具备良好的基本功，熟练使用基本的数据结构和算法，深入理解多线程、Socket等相关技术；3.具备良好的编码习惯，结构清晰，命名规范，逻辑性强，代码冗余率低；4.熟练掌握Django,Tornado，Sqlalchemy，Celery等主流框架，深入理解框架实现原理及特性；熟练使用python的常用库5.熟悉Python的高级特性，深入理解各种设计模式和应用场景。6.有大规模分布式系统的开发和高可用相关的实践经验，具备设计复杂系统的能力；7.熟练掌握MySQL数据库，具备MySQL索引优化、查询优化的能力；8.熟练掌握一种以上非关系型数据库，如Redis,Cassandra，理解其使用场景及限制；9.熟悉分布式系统，熟练掌握一种以上服务框架和消息中间件，了解其实现原理；10.熟悉Internet常用协议，如HTTP、TCP/IP、熟悉RESTful规范；11.有以下经验者优先：①具有golang实际工作经验；②具有大规模分布式系统的调优经验；③熟悉大规模分布式系统架构设计，熟悉CAP、Quorum、ConsistentHashing等原理和算法；']\n"
     ]
    }
   ],
   "source": [
    "job_description = soup.find_all(class_=\"content content-word\")[0].get_text().strip()\n",
    "# 薪水、学历要求、工作经验要求、招聘详细页url、公司名、公司 url\n",
    "info = soup.find_all(class_=\"job-title-left\")[0]\n",
    "salary = info.p.get_text().strip().split()[0]\n",
    "# line = [education, experience, language, age]\n",
    "line = [x.get_text() for x in info.div.find_all('span')]\n",
    "line.insert(0, salary)\n",
    "line.append(job_description)\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我应该被封了？'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.sleep(2)\n",
    "'我应该被封了？'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
